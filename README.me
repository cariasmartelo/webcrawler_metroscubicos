# Crawler and Scrapper of metroscubicos.com

## Required libraries:
- numpy
- pandas
- re
- ast
- queue
- time
- json
- bs4
- matplotlib
- geopandas
- shapely
- requests

## How to run the code:

To run a test of the crawler, scrapper and assign the distance meassures
with 100 houses and 100 apartmens, run the following function of main.py:

crawl_scrape_distance(100, 'test')

To run the predictive algorithm with all the dataset we downloaded (30,000 +),
run the following function of main.py

predict('./Intermediate_Files/results_with_metrodata.json')

To produce the visualizations run:
visualize()


## Description of the python scripts:

main.py: Main code to run all the project.

Crawler.py: Crawler and scrapper of the marketplace. It obtains all the
characteristics listed of the properties in the market, including price
number of rooms, number of bedrooms, amenities, location, area, etc.

It uses two classes: a Market class, which represents the market that results
from a search on the webpage, and a Crawler class, which represents a crawler 
of the market.

metroscubicos.com only displays 2000 results per search, even if the total number
of properties listed for a given search is more than that number. To overcome this,
the crawler is performed recursivelly. If the initial search has more than 2000 
results, the crawler recursivelly builds submarkets by applying filters. The result
of this is a structure similar to a "tree" of markets. With this structure, the market
crawl is also performes recursivelly, crawling and scrapping those markets that do not
have submarkets. 

distance.py: This code takes the results of the crawler and assigns to those properties
that have latitude and longitude the distance to the closest metro station, using the
estaciones-metro.json and the number of public goods within 5 km dnue_inegi_09.csv. 

prediction.py: This code takes the dataset with the distance measures assigned and
performs the predictive algorithms. Uses 2/3 of the data as training and 1/3 as test.
This code relies heavily in the scikit package.  

